{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import multi_dot as mdot\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cup\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datetime\n",
    "from ppt import utils\n",
    "from ppt.utils import attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "IMG_SIZE = 224\n",
    "_mean = [0.485, 0.456, 0.406]\n",
    "_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_trans = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(.3,.3,.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(_mean, _std),\n",
    "])\n",
    "val_trans = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(_mean, _std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppt.utils import DogsCatsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from C:\\Users\\tensorflow\\Desktop\\iloraz_inteligencji\\torch\\data\\raw\\dogscats\\sample/train.\n",
      "Loading data from C:\\Users\\tensorflow\\Desktop\\iloraz_inteligencji\\torch\\data\\raw\\dogscats\\sample/valid.\n"
     ]
    }
   ],
   "source": [
    "train_ds = DogsCatsDataset(r\"C:\\Users\\tensorflow\\Desktop\\iloraz_inteligencji\\torch\\data\\raw\", r\"sample/train\", transform=train_trans)\n",
    "val_ds = DogsCatsDataset(r\"C:\\Users\\tensorflow\\Desktop\\iloraz_inteligencji\\torch\\data\\raw\", r\"sample/valid\", transform=val_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=2\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = DogsCatsDataset(r\"C:\\Users\\tensorflow\\Desktop\\iloraz_inteligencji\\torch\\data\\raw\", r\"train\", transform=train_trans)\n",
    "# val_ds = DogsCatsDataset(r\"C:\\Users\\tensorflow\\Desktop\\iloraz_inteligencji\\torch\\data\\raw\", r\"valid\", transform=val_trans)\n",
    "# BATCH_SIZE=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frize all params\n",
    "for param in model.parameters():\n",
    "    param.requires_grad =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainig helpers\n",
    "def get_trainable(model_params):\n",
    "    return(p for p in model_params if p.requires_grad)\n",
    "\n",
    "def get_frozen(model_params):\n",
    "    return(p for p in model_params if not p.requires_grad)\n",
    "\n",
    "def all_trainable(model_params):\n",
    "    return all(p.requires_grad for p in model_params)\n",
    "# check if all params are frozen\n",
    "def all_frozen(model_params):\n",
    "    return all(not p.requires_grad for p in model_params)\n",
    "# freez all layers \n",
    "def freeze_all(model_params):\n",
    "    for param in model_params:\n",
    "        param.requires_grad = False\n",
    "        \n",
    "#list(get_trainable(model.parameters()))\n",
    "#list(get_frozen(model.parameters()))\n",
    "# all_trainable(model.parameters())\n",
    "# all_frozen(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_all(model.parameters())\n",
    "assert all_frozen(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replays last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(512, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_frozen(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_classes =2):\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    freeze_all(model.parameters())\n",
    "    model.fc = nn.Linear(512, n_classes)\n",
    "    return model\n",
    "\n",
    "model = get_model().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    get_trainable(model.parameters()),\n",
    "    lr = 0.001,\n",
    "    #momentum =0.9,\n",
    "    #model.fc.parameters(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "    batch loss: 0.735\n",
      "    batch loss: 0.631\n",
      "    batch loss: 0.528\n",
      "    batch loss: 0.456\n",
      "    batch loss: 0.436\n",
      "    batch loss: 0.901\n",
      "    batch loss: 0.593\n",
      "    batch loss: 0.398\n",
      "  Train Loss: 0.5847767405211926\n",
      "  Train Acc:  0.875\n",
      "  Valid Loss: 0.4822899326682091\n",
      "  Valid Acc:  0.875\n",
      "\n",
      "Epoch 2/2\n",
      "    batch loss: 0.252\n",
      "    batch loss: 0.275\n",
      "    batch loss: 0.623\n",
      "    batch loss: 0.926\n",
      "    batch loss: 0.415\n",
      "    batch loss: 0.646\n",
      "    batch loss: 0.771\n",
      "    batch loss: 0.733\n",
      "  Train Loss: 0.5799270533025265\n",
      "  Train Acc:  0.5625\n",
      "  Valid Loss: 0.4832411855459213\n",
      "  Valid Acc:  0.875\n",
      "\n",
      "Wall time: 4.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}/{N_EPOCHS}\")\n",
    "    model.train()\n",
    "    running_loss, correct = 0.0, 0\n",
    "    for X, y in train_dl:# we iterate over training data\n",
    "        X, y = X.to(device), y.to(device)# data do to gpu\n",
    "        optimizer.zero_grad()# zeroje gradienty\n",
    "        y_ = model(X)# data to model\n",
    "        loss = criterion(y_, y)# calculate loss\n",
    "        loss.backward()\n",
    "        optimizer.step()# call optimazer\n",
    "        # stats\n",
    "        print(f\"    batch loss: {loss.item():0.3f}\")\n",
    "        _, y_label_ = torch.max(y_,1)\n",
    "        correct += (y_label_ == y).sum().item()\n",
    "        running_loss += loss.item()*X.shape[0]\n",
    "        \n",
    "    print(f\"  Train Loss: {running_loss / len(train_dl.dataset)}\")\n",
    "    print(f\"  Train Acc:  {correct / len(train_dl.dataset)}\")\n",
    "    \n",
    "    # so now validation set\n",
    "    model.eval()\n",
    "    running_loss, correct = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_dl:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_ = model(X)\n",
    "            _, y_label_ = torch.max(y_,1)\n",
    "            correct += (y_label_ == y).sum().item()\n",
    "            loss = criterion(y_, y)\n",
    "            running_loss += loss.item()*X.shape[0]\n",
    "            \n",
    "    print(f\"  Valid Loss: {running_loss / len(val_dl.dataset)}\")\n",
    "    print(f\"  Valid Acc:  {correct / len(val_dl.dataset)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# traing liberys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CategoricalAccuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-69bed5040357>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mignite\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mignite\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCategoricalAccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'CategoricalAccuracy'"
     ]
    }
   ],
   "source": [
    "import ignite\n",
    "from ignite import CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
